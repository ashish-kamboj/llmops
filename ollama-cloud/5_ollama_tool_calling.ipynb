{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20da616",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "1. Create an Ollama account at [ollama.com](https://ollama.com)\n",
    "2. Generate an API key from [ollama.com/settings/keys](https://ollama.com/settings/keys)\n",
    "3. Set the API key in the `.env` file in this folder\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install ollama python-dotenv requests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2453f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-dotenv...\n",
      "✓ All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Install required packages and import libraries\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = ['ollama', 'python-dotenv', 'requests']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"✓ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e734ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama API configured\n",
      "  Endpoint: https://ollama.com\n",
      "  Default Model: gpt-oss:120b\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# Use Path.cwd() since __file__ is not defined in Jupyter notebooks\n",
    "env_path = Path.cwd() / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "else:\n",
    "    # Try to find .env in the ollama-cloud directory\n",
    "    load_dotenv(dotenv_path='d:\\\\ollama-n8n\\\\ollama-cloud\\\\.env')\n",
    "\n",
    "# Get API key and configuration\n",
    "OLLAMA_API_KEY = os.getenv('OLLAMA_API_KEY')\n",
    "OLLAMA_ENDPOINT = os.getenv('OLLAMA_API_ENDPOINT', 'https://ollama.com')\n",
    "DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'gpt-oss:120b')\n",
    "\n",
    "# Verify API key is set\n",
    "if not OLLAMA_API_KEY or OLLAMA_API_KEY == 'your_api_key_here':\n",
    "    print(\"WARNING: OLLAMA_API_KEY not set in .env file!\")\n",
    "    print(\"Please set your API key in the .env file: https://ollama.com/settings/keys\")\n",
    "else:\n",
    "    print(f\"✓ Ollama API configured\")\n",
    "    print(f\"  Endpoint: {OLLAMA_ENDPOINT}\")\n",
    "    print(f\"  Default Model: {DEFAULT_MODEL}\")\n",
    "\n",
    "# Initialize Ollama client for cloud API\n",
    "client = ollama.Client(\n",
    "    host=OLLAMA_ENDPOINT,\n",
    "    headers={'Authorization': f'Bearer {OLLAMA_API_KEY}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbc2aa",
   "metadata": {},
   "source": [
    "## Tool Calling Capability - Extend Models with Functions\n",
    "\n",
    "Tool calling allows models to request execution of custom functions. The model decides when and how to use tools based on the user's request.\n",
    "\n",
    "**Use Cases:**\n",
    "- Mathematical calculations\n",
    "- Database queries\n",
    "- API calls\n",
    "- Real-time data retrieval\n",
    "- Complex workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2968b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing tool calling with gpt-oss:120b...\n",
      "   Query: What is 17 × 23? Also, what is the square root of 529?\n",
      "\n",
      "   Model's Initial Response:\n",
      "   Content: \n",
      "\n",
      " Tool Calls Requested: 1\n",
      "\n",
      "   → Calling: multiply({'a': 17, 'b': 23})\n",
      "     Result: 391\n",
      "\n",
      "✓ Final Answer:\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_tool_calling(model: str = 'gpt-oss:120b', user_query: str = \"What is 17 × 23? Also, what is the square root of 529?\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test tool calling - models can request tool execution.\n",
    "    \n",
    "    Args:\n",
    "        model: Model with tool calling support\n",
    "        user_query: Question that requires tool use\n",
    "    \n",
    "    Returns:\n",
    "        Conversation with tool calls and results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define available tools\n",
    "    def multiply(a: float, b: float) -> float:\n",
    "        \"\"\"Multiply two numbers\"\"\"\n",
    "        return a * b\n",
    "    \n",
    "    def square_root(n: float) -> float:\n",
    "        \"\"\"Calculate square root\"\"\"\n",
    "        import math\n",
    "        return math.sqrt(n)\n",
    "    \n",
    "    def get_weather(location: str) -> str:\n",
    "        \"\"\"Get weather for a location (mock)\"\"\"\n",
    "        return f\"Weather in {location}: Sunny, 22°C\"\n",
    "    \n",
    "    # Define tools for the model\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"multiply\",\n",
    "                \"description\": \"Multiply two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"square_root\",\n",
    "                \"description\": \"Calculate the square root of a number\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"n\": {\"type\": \"number\", \"description\": \"The number to get square root of\"}\n",
    "                    },\n",
    "                    \"required\": [\"n\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get current weather for a location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"   Testing tool calling with {model}...\")\n",
    "    print(f\"   Query: {user_query}\\n\")\n",
    "    \n",
    "    # Map function names to actual functions\n",
    "    available_functions = {\n",
    "        'multiply': multiply,\n",
    "        'square_root': square_root,\n",
    "        'get_weather': get_weather\n",
    "    }\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': user_query}]\n",
    "    conversation_history = []\n",
    "    \n",
    "    # Initial request with tools\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    print(f\"   Model's Initial Response:\")\n",
    "    print(f\"   Content: {response.message.content}\")\n",
    "    \n",
    "    # Check for tool calls\n",
    "    if hasattr(response.message, 'tool_calls') and response.message.tool_calls:\n",
    "        print(f\"\\n Tool Calls Requested: {len(response.message.tool_calls)}\")\n",
    "        \n",
    "        # Process each tool call\n",
    "        for tool_call in response.message.tool_calls:\n",
    "            func_name = tool_call.function.name\n",
    "            func_args = tool_call.function.arguments\n",
    "            \n",
    "            print(f\"\\n   → Calling: {func_name}({func_args})\")\n",
    "            \n",
    "            # Execute the function\n",
    "            if func_name in available_functions:\n",
    "                result = available_functions[func_name](**func_args)\n",
    "                print(f\"     Result: {result}\")\n",
    "                \n",
    "                # Add tool result to conversation\n",
    "                messages.append(response.message)\n",
    "                messages.append({\n",
    "                    'role': 'tool',\n",
    "                    'content': str(result),\n",
    "                    'tool_name': func_name\n",
    "                })\n",
    "    \n",
    "    # Get final response if tools were used\n",
    "    if len(messages) > 1:\n",
    "        final_response = client.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=False\n",
    "        )\n",
    "        print(f\"\\n✓ Final Answer:\")\n",
    "        print(f\"   {final_response.message.content}\\n\")\n",
    "        return {\n",
    "            'initial_response': response.message.content,\n",
    "            'tool_calls': [tc.function.name for tc in (response.message.tool_calls or [])],\n",
    "            'final_response': final_response.message.content\n",
    "        }\n",
    "    \n",
    "    return {'response': response.message.content, 'tool_calls': []}\n",
    "\n",
    "# Test tool calling\n",
    "tool_result = test_tool_calling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
